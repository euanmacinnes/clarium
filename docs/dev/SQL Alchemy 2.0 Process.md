### Overview
Below is a focused, practical deep dive into what SQLAlchemy (2.0+) typically does at the database level for the four operations you listed. The emphasis is on the PostgreSQL dialect because many clients (including your repo’s tests) exercise pg_catalog/information_schema paths that mirror PostgreSQL.

I’ll cover:
- Concrete actions and typical SQL issued
- Settings read/analysed
- Object resolution logic (schemas, search_path, temp schemas)
- Edge cases and configuration flags that affect the behavior

---

### 1) `insp = inspect(engine)`
Creating an `Inspector` is a lightweight Python-side factory. The heavy lifting begins when you actually call methods on the inspector. However, as soon as the first call occurs, the PostgreSQL dialect may fetch some server settings and capability flags.

Likely actions and settings analysis (triggered lazily on first use):
- Detect server version
  - Prefer DBAPI-native version (psycopg: `server_version`); else query:
    - Example SQL: `SHOW server_version` or `SELECT version()`
  - Used to decide features like `IDENTITY` vs `SERIAL`, ON CONFLICT support, generated columns, etc.
- Check string literal behavior
  - Example SQL: `SHOW standard_conforming_strings` (expect `on` on modern PG)
  - Affects SQL compiler string escaping rules.
- Determine default/current schema and search path
  - Example SQL: `SHOW search_path` and/or `SELECT current_schema()`
  - Used for unqualified name resolution.
- Introspection caches
  - An in-memory info cache (if passed) may be used to memoize results of catalog queries during the session.

No DDL is executed at this point; these are read-only metadata probes.

---

### 2) `insp.has_table(table_name)`
This answers “does a table (or relation) of a supported kind exist that matches this name?” Behavior depends on arguments:
- Parameters: `table_name: str`, optional `schema: str | None` (via `insp.has_table(name, schema=schema)` in 2.x)
- If `schema` is None: resolution occurs against the active `search_path`
- If `schema` is provided: resolution is schema-qualified (no search_path fallback)

Dialects may implement this via efficient catalog helpers. On PostgreSQL the common patterns are:

Typical PostgreSQL strategies and SQL
- Via `to_regclass()` for unquoted, search-path aware lookup:
  - When `schema` is None:
    - SQL: `SELECT to_regclass(:tablename)`
      - Bind: `public.my_table` if you pass a dotted string, but typically SQLAlchemy composes the regclass from `table_name` and current `search_path` rules; alternatively, it may use a pg_class join (see next).
    - Result non-NULL implies existence of any relation (table, view, materialized view, sequence, etc.). Dialect may filter by relkind if it needs specifically “tables”.
  - When `schema` is provided:
    - SQL: `SELECT to_regclass(:schema || '.' || :tablename)`
- Via explicit catalogs when distinguishing table kinds:
  - SQL:
    ```sql
    SELECT 1
    FROM pg_catalog.pg_class c
    JOIN pg_catalog.pg_namespace n ON n.oid = c.relnamespace
    WHERE c.relname = :table_name
      AND n.nspname = :schema_name -- omitted if schema None
      AND c.relkind IN ('r','p')   -- base table and partitioned table
    LIMIT 1
    ```
  - Some variants also include views/materialized views when checking generically for “has table or view”, but `has_table` usually targets base/partitioned tables only.

Identifier normalization
- Unquoted SQL identifiers are folded to lower-case in PostgreSQL; SQLAlchemy mirrors this. If you created a table with a quoted, mixed-case name, you must pass the exact case, and the dialect will compare against `pg_class.relname` with quotes applied.

Temp tables
- Temporary tables live in a temp schema such as `pg_temp_3`. If `schema=None`, `search_path` typically includes the session’s temp schema, so `has_table` will return true for a temp table of the same name. If you pass `schema="public"`, temp tables won’t be seen.

Permissions
- Catalog tables are world-readable on PostgreSQL; `has_table` does not require object privileges on the table itself, only catalog read access.

Edge behavior
- If the connection has a non-default `search_path`, results will follow that. Example: if `search_path = myschema, public` and both `myschema.foo` and `public.foo` exist, `has_table("foo")` is true because the first match in the path exists.

---

### 3) `new_table = Table(table_name, metadata, *cols)`
This is purely client-side until you emit DDL (e.g., via `create_all`). Key effects:
- The `Table` object records name, optional `schema`, columns, types, constraints (PK, FK, Unique), indexes (attached later), comments, and per-dialect options.
- Column types may carry PostgreSQL specifics (e.g., `postgresql.ENUM`, `JSONB`, `ARRAY`).
- Autoincrement strategy: in SQLAlchemy 2.x for PostgreSQL ≥ 10, Integer PKs default to `GENERATED BY DEFAULT AS IDENTITY` unless `use_native_hstore/serial` legacy switches are in play; explicit `Sequence` overrides this and emits `CREATE SEQUENCE`.
- No SQL is executed yet.

---

### 4) `metadata.create_all(engine, [new_table])`
This is where SQL is emitted. The process is nuanced and involves pre-checks, dependency ordering, DDL batching, and post-creation steps.

High-level flow
1) Dependency planning
   - SQLAlchemy topologically sorts the given tables by foreign-key dependencies so referenced tables are created first. This is computed from the `Table` objects; it doesn’t need server queries for this step.

2) `checkfirst` existence checks (default `True`)
   - For each table, the dialect asks “does it exist?” using a method similar to `Inspector.has_table`.
   - If it exists, no `CREATE TABLE` is issued (for that table). Note: SQLAlchemy generally does not rely on `CREATE TABLE IF NOT EXISTS`; it prefers pre-check queries to avoid dialect differences and to handle reflection-driven side effects.
   - These checks may also reflect related elements (types, sequences) as needed.

3) Type/auxiliary object preparation (PostgreSQL specifics)
   - ENUM types: if a column uses `postgresql.ENUM`, SQLAlchemy emits `CREATE TYPE <schema>.<enumname> AS ENUM (...)` first (with `checkfirst` for the type). If the enum exists, it may compare labels depending on configuration and raise or ignore label diffs.
   - Sequences: if a column uses an explicit `Sequence`, emit `CREATE SEQUENCE` prior to table creation (with `checkfirst`).
   - Identity columns: no separate object creation; identity is inline in `CREATE TABLE`.

4) Emit `CREATE TABLE`
   - Representative SQL (PostgreSQL ≥ 10):
     ```sql
     CREATE TABLE "public"."my_table" (
         id INTEGER GENERATED BY DEFAULT AS IDENTITY,
         name VARCHAR(255) NOT NULL,
         created_at TIMESTAMP WITH TIME ZONE,
         CONSTRAINT my_table_pkey PRIMARY KEY (id),
         CONSTRAINT my_table_fk_parent FOREIGN KEY (parent_id)
             REFERENCES "public"."parent" (id)
     )
     ```
   - If there are schema-qualified names, they are emitted with quotes. Nullability, defaults, server_default expressions, and constraints are included inline where possible.

5) Post table creation objects
   - Indexes defined on the `Table` (via `Index(...)`) are emitted with `CREATE INDEX` statements after `CREATE TABLE`.
   - Unique constraints may be emitted inline or as separate `ALTER TABLE ADD CONSTRAINT`, depending on dialect and naming.
   - Comments: if set (table/column), emitted via `COMMENT ON TABLE/COMMENT ON COLUMN`.

6) Transaction behavior
   - By default, SQLAlchemy executes DDL inside a transaction (it will `BEGIN` and `COMMIT` through the connection/engine). PostgreSQL supports transactional DDL, so all the steps above are atomic if left in one transaction.
   - If you explicitly use autocommit or manage transactions manually, behavior follows your settings.

7) Reflection side-effects (when `checkfirst=True`)
   - Before creation, existence checks can trigger catalog reads of existing objects (tables, types, sequences), commonly via:
     - `information_schema.tables`
     - `pg_catalog.pg_class/pg_namespace/pg_attribute/pg_constraint`
     - `to_regclass()`/`to_regtype()` helpers

Representative queries (typical patterns)
- Table existence (schema-qualified):
  ```sql
  SELECT 1
  FROM pg_catalog.pg_class c
  JOIN pg_catalog.pg_namespace n ON n.oid = c.relnamespace
  WHERE c.relname = %(name)s AND n.nspname = %(schema)s AND c.relkind IN ('r','p')
  LIMIT 1
  ```
- Enum type existence:
  ```sql
  SELECT t.typname
  FROM pg_catalog.pg_type t
  JOIN pg_catalog.pg_namespace n ON n.oid = t.typnamespace
  WHERE n.nspname = %(schema)s AND t.typname = %(enum_name)s
  ```
- Information schema listing (alternative/legacy table checks):
  ```sql
  SELECT table_name
  FROM information_schema.tables
  WHERE table_schema = %(schema)s AND table_type IN ('BASE TABLE','PARTITIONED TABLE')
  ```

Configuration and flags that influence behavior
- `checkfirst=True` (default): controls whether pre-existence queries run.
- `Table.schema`: if set, creation is schema-qualified; else uses the connection’s `search_path` and default schema resolution.
- `schema_translate_map`: can rewrite schemas at compile time (useful for multi-tenant or test schemas).
- Autoincrement strategy:
  - PostgreSQL 10+: identity columns by default (`GENERATED BY DEFAULT AS IDENTITY`).
  - Legacy `SERIAL` can be forced via `postgresql_use_serial=True` on the dialect or per-column options.
- Isolation/transaction options on the `Engine`/`Connection` can lead to explicit `BEGIN/COMMIT` around DDL.

Error handling
- If `checkfirst=True` and the table already exists with a conflicting definition, SQLAlchemy won’t auto-diff/alter it during `create_all`; it simply skips creation. Migrations/alterations are the domain of Alembic.

---

### Putting your snippet together
Given:
```python
insp = inspect(engine)
insp.has_table(table_name)
new_table = Table(table_name, metadata, *cols)
metadata.create_all(engine, [new_table])
```

- `inspect(engine)` prepares an inspector; the first catalog call will likely fetch server version, `standard_conforming_strings`, and the active schema/search path.
- `insp.has_table(table_name)` issues either a `to_regclass()` lookup or a `pg_class`/`pg_namespace` query, honoring `search_path` or a provided `schema`.
- `Table(...)` builds metadata client-side; no SQL.
- `create_all(...)` with a single table will:
  1) Check if the table exists (catalog query).
  2) If needed, create prerequisite objects (ENUM/SEQUENCE) with their own `checkfirst` queries.
  3) Emit `CREATE TABLE ...`, followed by any indexes and comments.
  4) Wrap this in a transaction by default.

---

### Practical tips and edge cases
- Always pass `schema="public"` to `has_table` if you need to avoid `search_path` ambiguity, especially when temp schemas may be involved.
- For mixed-case or non-standard identifiers created with quotes, pass the exact case in names or set `quote=True` in `Column`/`Table` constructs.
- When using `postgresql.ENUM`, prefer creating it once at metadata scope, reuse it across columns, and allow SQLAlchemy to `CREATE TYPE` before tables.
- If you rely on `IF NOT EXISTS` semantics at the SQL level, note that SQLAlchemy’s `create_all` generally chooses pre-checks rather than inline `IF NOT EXISTS` across dialects.
- For clean reproducible DDL runs, keep `search_path` narrow: e.g., `SET search_path TO public;` or set schema on your `Table` objects.

---

### Minimal example with explicit schema
```python
from sqlalchemy import create_engine, inspect, MetaData, Table, Column, Integer, String

engine = create_engine("postgresql+psycopg://...")
metadata = MetaData()

new_table = Table(
    "demo",
    metadata,
    Column("id", Integer, primary_key=True),
    Column("name", String(255), nullable=False),
    schema="public",
)

insp = inspect(engine)
exists = insp.has_table("demo", schema="public")
print("exists?", exists)

metadata.create_all(engine, [new_table])  # emits CREATE TYPE/SEQUENCE if needed, CREATE TABLE, CREATE INDEX, COMMENT
```

This aligns with what SQLAlchemy will probe and emit under the hood on PostgreSQL, and matches the pg_catalog/information_schema access patterns reflected in your repository’s tests and docs.